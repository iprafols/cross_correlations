"""
Module to process the outputs of the cross-correlation code

DESCRIPTION:
This module provides the classes CorrData, CorrModel, CorrDataError,
CorrDataWarning, CorrModelError, and CorrelationProcessError
to enable easy treatment of the outputs of the cross-correlation code. The first 
two classes are for data and model treatment and the others are for handling errors 
and warnings.
See the specific documentation of each of the classes for details.

The module provides a function to display the documentation of the different 
classes, mehtods, and functions called showDocumentation. Type 
showDocumentation(showDocumentation) for details on its behaviour.

CLASSES:
    CorrData
    CorrDataWarning
    CorrDataError
    CorrModel
    CorrModelError
    CorrelationProcessError
    
FUNCTIONS:
    plot
    rebinIgnoringCovMat
    showDocumentation
    trim

TO DO:
    Add test capabilities
"""
import warnings
import inspect
import sys
import difflib
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors
from matplotlib.colors import colorConverter
import matplotlib.gridspec as gridspec
from matplotlib.ticker import MultipleLocator, FormatStrFormatter, NullFormatter, ScalarFormatter

__author__ = 'Ignasi Perez-Rafols'
__copyright__ = 'CC by-nc-sa'
__credits__ = ['Ignasi Perez-Rafols']
__license__ = 'GPL'
__version__ = '1.0.1'
__maintainer__ = 'Ignasi Perez-Rafols'
__email__ = 'iprafols@icc.ub.edu'
__status__ = 'Production'

class CorrData(object):
    """
    Manage the data generated by the cross-correlation code.
    
    CLASS: CorrData
    PURPOSE: 
        Manage the data generated by the cross-correlation code
    PUBLIC METHODS:
        __init__(filename, pi, sigma)
        computeTransformationMatrix(new_pi, new_sigma, keep_matrix=False)
        rebinData(transformation_matrix, keep_results=False, rebin_grid=True)
        whichBins(sigma_min, sigma_max, rebinned=False)
        cov_mat(rebinned=False)
        error(rebinned=False)
        data_mat(rebinned=False)
        grid_pi_mat(rebinend=False)
        grid_sigma_mat(rebinned=False)
        has_grid()
        pi(rebinned=False)
        sigma(rebinned=False)
    PRIVATE METHODS (should not be called except by class methods):
        _formatData(self)
    PRIVATE VARIABLES (should not be accessed except by class methods):
        _data (structured np.ndarray]):         Contains the measurement of the cross-correlation for the 
                                                different bins
        _data_mat (np.ndarray):                 Matrix form of _data
        _cov (structured np.ndarray):           Contains the measurement of the covariance matrix for the 
                                                different bins
        _cov_mat (np.ndarray):                  Matrix form of _cov
        _grid (structured np.ndarray):          Contains the grid layout for the different bins. Ignored if 
                                                _has_grid is False
        _grid_pi_mat (np.ndarray):              Matrix form of the values of parallel separation from _grid.
                                                If _has_grid is False, the values are computed from _pi and 
                                                _sigma
        _grid_sigma_mat (np.ndarray):           Matrix form of the values of perpendicular separation from
                                                _grid. If _has_grid is False, the values are computed from 
                                                _pi and _sigma
        _grid_z_mat (np.ndarray):               Matrix form of the values of the redshift from _grid. Ignored 
                                                if _has_grid is False
        _dist (structured np.ndarray):          Contains the measurement of the distortion matrix. Ignored
                                                if _has_dist is False
        _dist_mat (np.ndarray):                 Matrix form of _dist. Ignored if _has_dist is False
        _has_grid (boolean):                    True if the grid layout is specified, False otherwise
        _has_dmat (boolean):                    True if the distortion matrix is specified, False otherwise
        _pi (np.ndarray):                       An array specifying the limits of the parallel separation 
                                                bins
        _sigma (np.ndarray]):                   An array specifying the limits of the perpendicular 
                                                separation bins
        _transformatiom_matrix (np.ndarray):    An array containing the conversion to the last specified 
                                                binning
        _pi_new (np.ndarray):                   An array containing the rebinned bins in pi
        _sigma_new (np.ndarray):                An array containing the rebinned bins in sigma
        _cov_mat_new (np.ndarray):              An array containing the rebinned version of _cov_mat
        _data_mat_new (np.ndarray):             An array containing the rebinned version of _data_mat
        _grid_pi_mat_new (np.ndarray):          An array containing the rebinned version of _grid_pi_mat.
        _grid_sigma_mat_new (np.ndarray):       An array containing the rebinned version of _grid_sigma_mat.
        _grid_z_mat_new (np.ndarray):           An array containing the rebinned version of _grid_z_mat.
                                                Ignored if _has_grid is False
    ASSOCIATED WARNING AND ERORR CLASSES:
        CorrDataWarning
        CorrDataError
    """

    def __init__(self, filename, pi, sigma):
        """
        Initialize class instance.
        
        FUNCTION: CorrData.__init__
        TYPE: Constructor, public
        PURPOSE: 
            Initialize class instance
        ARGUMENTS:
            filename (string):  Name of the file containing the data to process (without the extension)
            pi (np.ndarray):    Intervals of parallel separation at which the data was measured
            sigma (np.ndarray): Intervals of perpendicular separation at which the data was measured
        RETURNS:
            A initialized instance of CorrData
        EXCEPTION SAFETY:
            Raises a CorrDataError instance if the arguments are of incorrect type, data is not readable
            or data shapes are not consistent. Prints a CorrDataWarning if the specified bin ranges are
            not consistent with the read data. The instance is still formed after the warning, but some
            features may produce unexpected results
        EXAMPLES:
            data = CorrData("my_measurement", np.arange(-80, 80 + 2, 2), np.arange(0, 80 + 2, 2))
        """
        # check parameters' types
        if not (type(filename) == str):
            raise CorrDataError(self.__init__, 'Incorrect type of the parameter "filename". Could not generate instance')
        if not (isinstance(pi, np.ndarray)):
            raise CorrDataError(self.__init__, 'Incorrect type of the parameter "pi". Could not generate instance')
        if not (isinstance(sigma, np.ndarray)):
            raise CorrDataError(self.__init__, 'Incorrect type of the parameter "sigma". Could not generate instance')
        
        # read data
        try:
            self._data = np.genfromtxt(filename + '.data', dtype=[('index', int), ('value', float)])
            self._cov = np.genfromtxt(filename + '.cov', dtype=[('index1', int), ('index2', int), ('value', float)])
        except IOError as ioerror:
            raise CorrDataError(self.__init__, str(ioerror).split(']')[-1])
        
        # read grid
        try:
            self._grid = np.genfromtxt(filename + '.grid', dtype=[('index', int),
                                                                  ('pi', float),
                                                                  ('sigma', float),
                                                                  ('z', float)])
            self._has_grid = True
        # if there is no grid, just assume the middle values of the specified intervals
        except IOError:
            self._grid = np.array([ (i * (sigma.size - 1) + j, (pi[i] + pi[i + 1]) / 2.0, (sigma[j] + sigma[j + 1]) / 2.0) for i in range(0, pi.size - 1) for j in range(0, sigma.size - 1) ], dtype=[('index', int), ('pi', float), ('sigma', float)])
            self._has_grid = False
        
        # read distortion matrix
        try:
            self._dist = np.genfromtxt(filename + '.dmat', dtype=[('index1', int), ('index2', int), ('value', float)])
            self._has_dist = True
        except IOError:
            self._has_dist = False
        
        # format data into matrixes
        self._formatData()
        # check that matrix shapes are consistent
        if not (self._cov_mat.shape[0] == self._data_mat.size):
            raise CorrDataError(self.__init__, 'Read cov_mat and data have shapes that are not consistent. cov_mat.shape = {}, data.shape = {}'.format(self._cov_mat.shape, self._data_mat.shape))
        if not (self._grid_pi_mat.size == self._data_mat.size):
            raise CorrDataError(self.__init__, 'Read grid_pi_mat and data have shapes that are not consistent. grid_pi_mat.shape = {}, data.shape = {}'.format(self._grid_pi_mat.shape, self._data_mat.shape))
            if not (self._grid_sigma_mat.size == self._data_mat.size):
                raise CorrDataError(self.__init__, 'Read grid_sigma_mat and data have shapes that are not consistent. grid_sigma_mat.shape = {}, data.shape = {}'.format(self._grid_sigma_mat.shape, self._data_mat.shape))
        if self._has_grid:
            if not (self._grid_z_mat.size == self._data_mat.size):
                raise CorrDataError(self.__init__, 'Read grid_z_mat and data have shapes that are not consistent. grid_z_mat.shape = {}, data.shape = {}'.format(self._grid_z_mat.shape, self._data_mat.shape))
        if self._has_dist:
            if not (self._dist_mat.shape[0] == self._data_mat.size):
                raise CorrDataError(self.__init__, 'Read dist_mat and data have shapes that are not consistent. dist_mat.shape = {}, data.shape = {}'.format(self._dist_mat.shape, self._data_mat.shape))

        # save intervals for later usage
        self._pi = np.copy(pi)
        self._sigma = np.copy(sigma)
        try:
            assert (self._pi.size - 1) * (self._sigma.size - 1) == self._data_mat.size
        except AssertionError:
            warnings.warn(CorrDataWarning(self.__init__, 'The specified intervals are ill-formed. This may lead to unexpected behaviour'))
    
    def _formatData(self):
        """
        Formats current data into operable matrixes.
        
        FUNCTION: CorrData._formatData
        TYPE: Private (to be accessed from class member functions only)
        PURPOSE: 
            Formats current data into operable matrixes. Formatted matrixes are stored as new 
            instance members and are not linked with the original arrays.
        EXAMPLES:
            self._formatData()
        """
        self._data_mat = np.copy(self._data['value'])
        self._cov_mat = np.zeros((np.amax([self._cov['index1'], self._cov['index2']]) + 1, np.amax([self._cov['index1'], self._cov['index2']]) + 1))
        for index1, index2, value in self._cov:
            self._cov_mat[index1][index2] = value
            self._cov_mat[index2][index1] = value

        self._grid_pi_mat = np.copy(self._grid['pi'])
        self._grid_sigma_mat = np.copy(self._grid['sigma'])
        if self._has_grid:
            self._grid_z_mat = np.copy(self._grid['z'])
        if self._has_dist:
            self._dist_mat = np.zeros((np.amax([self._dist['index1'], self._dist['index2']]) + 1, np.amax([self._dist['index1'], self._dist['index2']]) + 1))
            for index1, index2, value in self._dist:
                self._dist_mat[index1][index2] = value
                self._dist_mat[index2][index1] = value

    def computeTransformationMatrix(self, new_pi, new_sigma, keep_matrix = False):
        """
        Compute the transformation matrix from the data bins to the given bins.
        
        FUNCTION: CorrData.computeTransformationMatrix
        TYPE: Public
        PURPOSE: 
            Compute the transformation matrix from the data bins to the specified bins. The bins must be 
            wider than the original bins. Upon options may store the resulting matrix as a instance 
            attribute. Previous similar instances are deleted.
        ARGUMENTS:
            new_pi (np.ndarray):    An array specifying the limits of the parallel separation bins
            new_sigma (np.ndarray): An array specifying the limits of the perpendicular separation bins
        KEYWORD ARGUMENTS:
            keep_matrix (boolean):  If True, keeps the resulting transformation matrix and the new binning 
                                    as a private instance attributes -- Default: False
        RETURNS:
            The transformation matrix between the data bins to the specified bins
        EXCEPTION SAFETY:
            Raises a CorrDataError instance if the parameters don't have the correct type or if the 
            specified bins are smaller than the originals.
        EXAMPLES:
            data.computeTransformatiomMatrix(np.arange(-80, 80 + 4, 4), np.arange(0, 80+4, 4))
            data.computeTransformatiomMatrix(np.arange(-80, 80 + 4, 4), np.arange(0, 80+4, 4), keep_matrix=True)
            data.computeTransformatiomMatrix(np.arange(-80, 80 + 4, 4), np.arange(0, 80+4, 4), keep_matrix=False)
        """
        # check parameters' types
        if not (isinstance(new_pi, np.ndarray)):
            raise CorrDataError(self.computeTransformationMatrix, 'Incorrect type of the parameter "new_pi".')
        if not (isinstance(new_sigma, np.ndarray)):
            raise CorrDataError(self.computeTransformationMatrix, 'Incorrect type of the parameter "new_sigma".')
        if not (type(keep_matrix) == bool):
            raise CorrDataError(self.computeTransformationMatrix, 'Incorrect type of the parameter "keep_matrix".')

        # check parameters' consistency
        try:
            assert new_pi.size <= self._pi.size
            assert new_sigma.size <= self._sigma.size
        except AssertionError:
            raise CorrDataError(self.computeTransformationMatrix, 'Given bins are smaller than the originals.')

        # delete previous transformation instances if existent
        if hasattr(self, '_transformatiom_matrix'):
            del self._transformatiom_matrix
        if hasattr(self, '_pi_new'):
            del self._pi_new
        if hasattr(self, '_sigma_new'):
            del self._sigma_new
        
        
        transformation_matrix = np.zeros((self._data_mat.size, (new_pi.size - 1) * (new_sigma.size - 1)))
        
        # compute the relation between the old and new bins in parallel separation
        k_pi_conv = {}
        for k_pi in range(0, self._pi.size - 1):
            k_pi_new = 0
            try:
                aux = (self._pi[k_pi] + self._pi[k_pi + 1]) / 2.0
                while not (new_pi[k_pi_new] <= aux and aux <= new_pi[k_pi_new + 1]):
                    k_pi_new += 1
                    assert k_pi_new < new_pi.size - 1

            except AssertionError:
                continue

            k_pi_conv[k_pi] = k_pi_new
        
        # compute the relation between the old and new bins in perpendicular separation
        k_sigma_conv = {}
        for k_sigma in range(0, self._sigma.size - 1):
            k_sigma_new = 0
            try:
                aux = (self._sigma[k_sigma] + self._sigma[k_sigma + 1]) / 2.0
                while not (new_sigma[k_sigma_new] <= aux and aux <= new_sigma[k_sigma_new + 1]):
                    k_sigma_new += 1
                    assert k_sigma_new < new_sigma.size - 1

            except AssertionError:
                continue

            k_sigma_conv[k_sigma] = k_sigma_new

        # compute the overall relation between old and new bins, then fill the transformation matrix
        k_conv = {old_k_pi * (self._sigma.size - 1) + old_k_sigma:new_k_pi * (new_sigma.size - 1) + new_k_sigma for old_k_pi, new_k_pi in k_pi_conv.items() for old_k_sigma, new_k_sigma in k_sigma_conv.items()}
        for old, new in k_conv.items():
            transformation_matrix[old, new] = 1.0#"""
            
        # keep transformation instances
        if keep_matrix:
            self._transformatiom_matrix = np.copy(transformation_matrix)
            self._pi_new = np.copy(new_pi)
            self._sigma_new = np.copy(new_sigma)
        
        return transformation_matrix

    def rebinData(self, transformation_matrix, keep_results = False, rebin_grid = True):
        """
        Rebins the data to the specified binning
        
        FUNCTION: CorrData.rebinData
        TYPE: Public
        PURPOSE: 
            Rebins the data to the specified binning.
            The rebinning is performed as follows
        
            The covariance matrix is rebinned as
                C_{new}^{-1} = S^{t} C^{-1} S,
            where S is the specified transformation matrix
            
            The data (and possibly the grid) is rebinned as
                data_{new} = C_{new} S^{t} C^{-1} data
                
            The grid is only rebinned if rebinGrid is True. If, at the same time, _has_grid is 
            False, then the method returns empty matrix for the rebined grid. Upon options the
            method may store the resulting matrix as instance attributes. Previous similar instances
            are deleted.
            
        ARGUMENTS:
            transformation_matrix (np.ndarray): The matrix that will be used in the transformation
        KEYWORD ARGUMENTS:
            keep_results (boolean):             If True, keeps the resulting rebinned matrixes as
                                                private instances attributes -- Default: False
            rebin_grid (boolean):               If True, rebins the grid as well. In case _has_grid
                                                is False, returns empty matrixes for the rebinned grid
                                                -- Default: True
        RETURNS:
            The rebinned matrixes. The order is cov_mat_new, data_mat_new if rebinGrid is False and
            cov_mat_new, data_mat_new, grid_pi_mat_new, grid_sigma_mat_new, grid_z_mat_new otherwise
        EXCEPTION SAFETY:
            Raises a CorrDataError instance if the parameters don't have the correct type or if the specified 
            bins are smaller than the originals.
        EXAMPLES:
            cov_mat_new, data_mat_new, = data.rebinData(transf_matrix)
            cov_mat_new, data_mat_new, = data.rebinData(transf_matrix, keep_results=True)
            cov_mat_new, data_mat_new, = data.rebinData(transf_matrix, keep_results=False)
            cov_mat_new, data_mat_new, grid_pi_mat_new, 
                grid_sigma_mat_new, grid_z_mat_new = data.rebinData(transf_matrix)
            cov_mat_new, data_mat_new, grid_pi_mat_new,
                grid_sigma_mat_new, grid_z_mat_new = data.rebinData(transf_matrix, keep_results=True)
            cov_mat_new, data_mat_new, grid_pi_mat_new,
                grid_sigma_mat_new, grid_z_mat_new = data.rebinData(transf_matrix, keep_results=False)
        """
        # check parameters' types
        if not (isinstance(transformation_matrix, np.ndarray)):
            raise CorrDataError(self.rebinData, 'Incorrect type of the parameter "transformation_matrix".')
        if not (type(keep_results) == bool):
            raise CorrDataError(self.rebinData, 'Incorrect type of the parameter "keep_results".')
        if not (type(rebin_grid) == bool):
            raise CorrDataError(self.rebinData, 'Incorrect type of the parameter "rebin_grid".')
 
        # check parameters' consistency
        try:
            assert transformation_matrix.shape[0] == self._data_mat.size
        except AssertionError:
            raise CorrDataError(self.rebinData, 'Incorrect shape of transformation_matrix. Expected ({},), found {}'.format(self._data_mat.size, transformation_matrix.shape))

        # delele previous rebinned instances if present
        if hasattr(self, '_cov_mat_new'):
            del self._cov_mat_new
        if hasattr(self, '_data_mat_new'):
            del self._data_mat_new
        if hasattr(self, '_grid_pi_mat_new'):
            del self._grid_pi_mat_new
        if hasattr(self, '_grid_sigma_mat_new'):
            del self._grid_sigma_mat_new
        if hasattr(self, '_grid_z_mat_new'):
            del self._grid_z_mat_new

        # first, rebin the covariance matrix
        inv_cov_mat = np.linalg.inv(self._cov_mat)
        inv_cov_mat_new = np.dot(transformation_matrix.transpose(), np.dot(inv_cov_mat, transformation_matrix))
        cov_mat_new = np.linalg.inv(inv_cov_mat_new)

        # then rebin data and grid
        data_mat_new = np.dot(cov_mat_new, np.dot(transformation_matrix.transpose(), np.dot(inv_cov_mat, self._data_mat)))
        if rebin_grid:
            # rebin grid omitting covariance matrix
            inv_id_cov_mat = np.identity(self._cov_mat.shape[0], dtype=float)
            inv_id_cov_mat_new = np.dot(transformation_matrix.transpose(), np.dot(inv_id_cov_mat, transformation_matrix))
            id_cov_mat_new = np.linalg.inv(inv_id_cov_mat_new)

            grid_pi_mat_new = np.dot(id_cov_mat_new, np.dot(transformation_matrix.transpose(), self._grid_pi_mat))
            grid_sigma_mat_new = np.dot(id_cov_mat_new, np.dot(transformation_matrix.transpose(), self._grid_sigma_mat))
            if self._has_grid:
                grid_z_mat_new = np.dot(id_cov_mat_new, np.dot(transformation_matrix.transpose(), self._grid_z_mat))

        # TODO: finally rebin the distortion matrix

        # keep rebinned instances
        if keep_results:
            self._cov_mat_new = np.copy(cov_mat_new)
            self._data_mat_new = np.copy(data_mat_new)
            self._grid_pi_mat_new = np.copy(grid_pi_mat_new)
            self._grid_sigma_mat_new = np.copy(grid_sigma_mat_new)
            if self._has_grid:
                self._grid_z_mat_new = np.copy(grid_z_mat_new)

        if rebin_grid:
            if self._has_grid:
                return (cov_mat_new,
                 data_mat_new,
                 grid_pi_mat_new,
                 grid_sigma_mat_new,
                 grid_z_mat_new)
            else:
                return (cov_mat_new,
                 data_mat_new,
                 grid_pi_mat_new,
                 grid_sigma_mat_new,
                 np.array([]))
        else:
            return (cov_mat_new, data_mat_new)

    def whichBins(self, sigma_min, sigma_max, rebinned = False):
        """
        Determines which bins have perpedicular separations between sigma_min and sigma_max
            
        FUNCTION: CorrData.whichBins
        TYPE: Public
        PURPOSE: 
            Determines which bins have perpedicular separations between sigma_min and sigma_max.
            Bins with perpendicular separations equal to sigma_min are included and bins with
            perpendicular separations equal to sigma_max are excluded.
        ARGUMENTS:
            sigma_min (float): Minimum value of perpendicular separation to include a bin in the
                               return list
            sigma_max (float): Maximum value of perpendicular separation to include a bin in the
                               return list.
        KEYWORD ARGUMENTS:
            rebinned (bool):   If True, the rebinned matrixes will be considered except. If the
                               rebinned matrixes do not contain grid information, then this flag
                               is ignored. -- Default: False
        RETURNS: a np.where output with the position of the selected bins
        EXAMPLES:
            pos = data.whichBins(1.0, 3.0)
            pos = data.whichBins(1.0, 3.0, rebinned=True)
        """
        # check parameters' types
        if not (type(sigma_min) == float or isinstance(sigma_min, np.float64)):
            raise CorrDataError(self.whichBins, 'Incorrect type of the parameter "sigma_min".')
        if not (type(sigma_max) == float or isinstance(sigma_max, np.float64)):
            raise CorrDataError(self.whichBins, 'Incorrect type of the parameter "sigma_max".')
        if not (type(rebinned) == bool):
            raise CorrDataError(self.whichBins, 'Incorrect type of the parameter "rebinned".')

        # check parameters' consistency
        try:
            assert sigma_max > sigma_min
        except AssertionError:
            raise CorrDataError(self.whichBins, 'sigma_max is lower than sigma_min')

        if rebinned:
            if hasattr(self, '_grid_sigma_mat_new'):
                return np.where((self._grid_sigma_mat_new >= sigma_min) & (self._grid_sigma_mat_new < sigma_max))
        return np.where((self._grid_sigma_mat >= sigma_min) & (self._grid_sigma_mat < sigma_max))

    def cov_mat(self, rebinned = False):
        """
        Returns a copy of _cov_mat
        
        FUNCTION: CorrData.cov_mat
        TYPE: Access
        PURPOSE: Returns a copy of _cov_mat
        KEYWORD ARGUMENTS:
            rebinned: if True, returns a copy of _cov_mat_new instead. If _cov_mat_new does not exist,
                      then this flag is ignored
        RETURNS: A copy of _cov_mat
        EXAMPLES:
            cov_mat = data.cov_mat()
            cov_mat = data.cov_mat(rebinned=True)
        """
        if rebinned:
            if hasattr(self, '_cov_mat_new'):
                return np.copy(self._cov_mat_new)
        return np.copy(self._cov_mat)


    def data_mat(self, rebinned = False):
        """
        Returns a copy of _data_mat
        
        FUNCTION: CorrData.data_mat
        TYPE: Access
        PURPOSE: Returns a copy of _data_mat
        KEYWORD ARGUMENTS:
            rebinned: if True, returns a copy of _data_mat_new instead. If _data_mat_new does not exist,
                      then this flag is ignored
        RETURNS: A copy of _data_mat
        EXAMPLES:
            data_mat = data.data_mat()
            data_mat = data.data_mat(rebinned=True)
        """
        if rebinned:
            if hasattr(self, '_data_mat_new'):
                return np.copy(self._data_mat_new)
        return np.copy(self._data_mat)

    def error(self, rebinned = False):
        """
        Returns the square root of the diagonal elements of _cov_mat
        
        FUNCTION: CorrData.error()
        TYPE: Access
        PURPOSE: Returns the square root of the diagonal elements of _cov_mat
        KEYWORD ARGUMENTS:
            rebinned: if True, returns a copy of _cov_mat_new instead. If _cov_mat_new does
                      not exist, then this flag is ignored
        RETURNS: The square root of the diagonal elements of _cov_mat
        EXAMPLES:
            cov_mat = data.cov_mat_new()
            cov_mat = data.cov_new(rebinned=True)
        """
        if rebinned:
            if hasattr(self, '_cov_mat_new'):
                return np.sqrt(np.array([ self._cov_mat_new[index1, index1] for index1 in range(0, self._cov_mat_new.shape[0]) ]))
        return np.sqrt(np.array([ self._cov_mat[index1, index1] for index1 in range(0, self._cov_mat.shape[0]) ]))

    def grid_pi_mat(self, rebinned = False):
        """
        Returns a copy of _grid_pi_mat
            
        FUNCTION: CorrData.grid_pi_mat()
        TYPE: Access
        PURPOSE: Returns a copy of _grid_pi_mat
        KEYWORD ARGUMENTS:
            rebinned: if True, returns a copy of _grid_pi_mat_new instead. If _grid_pi_mat_new does
                      not exist, then this flag is ignored
        RETURNS: A copy of _grid_pi_mat
        EXAMPLES:
            grid_pi_mat = data.grid_pi_mat()
            grid_pi_mat = data.grid_pi_mat(rebinned=True)
        """
        if rebinned:
            if hasattr(self, '_grid_pi_mat_new'):
                return np.copy(self._grid_pi_mat_new)
        return np.copy(self._grid_pi_mat)

    def grid_sigma_mat(self, rebinned = False):
        """
        Returns a copy of _grid_sigma_mat
        
        FUNCTION: CorrData.grid_sigma_mat()
        TYPE: Access
        PURPOSE: Returns a copy of _grid_sigma_mat
        KEYWORD ARGUMENTS:
        rebinned: if True, returns a copy of _grid_sigma_mat_new instead. If _grid_sigma_mat_new does
        not exist, then this flag is ignored
        RETURNS: A copy of _grid_sigma_mat
        EXAMPLES:
        grid_pi_mat = data.grid_sigma_mat()
        grid_pi_mat = data.grid_sigma_mat(rebinned=True)
        """
        if rebinned:
            if hasattr(self, '_grid_sigma_mat_new'):
                return np.copy(self._grid_sigma_mat_new)
        return np.copy(self._grid_sigma_mat)

    def has_grid(self):
        """
        Returns the current value of _has_grid
        
        FUNCTION: CorrData.has_grid
        TYPE: Access
        PURPOSE: Returns the current value of _has_grid
        RETURNS: current value of _has_grid
        EXAMPLES:
            has_grid = data.has_grid()
        """
        return self._has_grid
    
    def pi(self, rebinned = False):
        """
            Returns a copy of _pi
            
            FUNCTION: CorrData.pi()
            TYPE: Access
            PURPOSE: Returns a copy of _pi
            KEYWORD ARGUMENTS:
            rebinned: if True, returns a copy of _pi_new instead. If _pi_new does not exist,
            then this flag is ignored
            RETURNS: A copy of _pi
            EXAMPLES:
            pi = data.pi()
            pi = data.pi(rebinned=True)
            """
        if rebinned:
            if hasattr(self, '_pi_new'):
                return np.copy(self._pi_new)
        return np.copy(self._pi)

    def sigma(self, rebinned = False):
        """
        Returns a copy of _sigma
        
        FUNCTION: CorrData.sigma()
        TYPE: Access
        PURPOSE: Returns a copy of _sigma
        KEYWORD ARGUMENTS:
            rebinned: if True, returns a copy of _sigma_new instead. If _sigma_new does not exist,
                      then this flag is ignored
        RETURNS: A copy of _sigma
        EXAMPLES:
            sigma = data.sigma()
            sigma = data.sigma(rebinned=True)
        """
        if rebinned:
            if hasattr(self, '_sigma_new'):
                return np.copy(self._sigma_new)
        return np.copy(self._sigma)


class CorrDataWarning(Warning):
    """
    Manage warnings related to CorrData
    
    CLASS: CorrDataWarning
    PURPOSE: 
        Manage warnings related to CorrData
    PUBLIC FUNCTIONS:
        __init__(filename, pi, sigma)
        __str__()
    PRIVATE VARIABLES (should not be accessed outside the class body):
        _method (CorrData method): Mehtod of CorrData that produced the warning
        _message (string):         Warning message
    """

    def __init__(self, method, message):
        """
        Initialize class instance
        
        FUNCTION: CorrDataWarning.__init__
        TYPE: Constructor, public
        PURPOSE: 
            Initialize class instance
        ARGUMENTS:
            method (CorrData method): Mehtod of CorrData that produced the warning
            message (string):         The warning message
        RETURNS:
            A initialized instance of CorrDataWarning
        EXAMPLES:
            warning = CorrDataWarning("this is a warning")
        """
        self._method = method.__name__
        self._message = message

    def __str__(self):
        """
        Returns a printable representation of the warning message
        
        FUNCTION: CorrDataWArning.__str__
        TYPE: Public
        PURPOSE: 
            Returns a printable representation of the warning message
        RETURNS:
            A printable representation of the warning message
        EXAMPLES:
            print CorrDataWarning("this is a warning")
        """
        return 'In method {method}: {message}'.format(method=self._method, message=repr(self._message))


class CorrDataError(Exception):
    """
    CorrData Exception
    
    CLASS: CorrDataError
    PURPOSE: CorrData Exception
    PUBLIC FUNCTIONS:
        __init__(filename, pi, sigma)
        __str__()
    PRIVATE VARIABLES (should not be accessed outside the class body):
        _method (CorrData method): Mehtod of CorrData that produced the error
        _message (string):         Error message
    """

    def __init__(self, method, message):
        """
        Initialize class instance
        
        FUNCTION: CorrDataError.__init__
        TYPE: Constructor, public
        PURPOSE: Initialize class instance
        ARGUMENTS:
            method (CorrData method):  Mehtod of CorrData that produced the error
            message (string):          The error message
        RETURNS:
            A initialized instance of CorrDataError
        EXAMPLES:
            error = CorrDataError("this is an error")
        """
        self._method = method.__name__
        self._message = message

    def __str__(self):
        """
        Returns a printable representation of the error message
        
        FUNCTION: CorrDataError.__str__
        TYPE: Public
        PURPOSE: Returns a printable representation of the error message
        RETURNS:
            A printable representation of the error message
        EXAMPLES:
            print CorrDataError("this is a warning")
        """
        return 'In method {method}: {message}'.format(method=self._method, message=repr(self._message))


class CorrModel(object):
    """
    Manage the models generated by the baofit code.
        
    CLASS: CorrModel
    PURPOSE:
        Manage the models generated by the baofit code
    PUBLIC METHODS:
        __init__(filename, pi, sigma)
        computeTransformationMatrix(new_pi, new_sigma, keep_matrix=False)
        rebinData(transformation_matrix, keep_results=False, rebin_grid=True)
        whichBins(sigma_min, sigma_max, rebinned=False)
        model_mat(rebinned=False)
        grid_pi_mat(rebinend=False)
        grid_sigma_mat(rebinned=False)
    PRIVATE METHODS (should not be called except by class methods):
        _formatData(self)
    PRIVATE VARIABLES (should not be accessed except by class methods):
        _model (structured np.ndarray]):        Contains the contents of the baofit residuals files
        _model_mat (np.ndarray):                Matrix form of the model
        _data_mat (np.ndarray:                  Matrix form of data to which the model was read
        _index_mat (np.ndarray):                Matrix form of the indexes used in the modelling
        _grid_pi_mat (np.ndarray):              Matrix form of the values of parallel separation
        _grid_sigma_mat (np.ndarray):           Matrix form of the values of perpendicular separation
        _grid_z_mat (np.ndarray):               Matrix form of the values of the redshift
        _transformatiom_matrix (np.ndarray):    An array containing the conversion to the last specified
                                                binning
        _model_mat_new (np.ndarray):            An array containing the rebinned version of _model_mat
        _data_mat_new (np.ndarray):             An array containing the rebinned version of _data_mat
        _grid_pi_mat_new (np.ndarray):          An array containing the rebinned version of _grid_pi_mat.
                                                Ignored if _has_grid is False
        _grid_sigma_mat_new (np.ndarray):       An array containing the rebinned version of _grid_sigma_mat.
                                                Ignored if _has_grid is False
        _grid_z_mat_new (np.ndarray):           An array containing the rebinned version of _grid_z_mat.
                                                Ignored if _has_grid is False
    ASSOCIATED WARNING AND ERORR CLASSES:
        CorrModelError
    """

    def __init__(self, filename):
        """
        Initialize class instance.
        
        FUNCTION: CorrData.__init__
        TYPE: Constructor, public
        PURPOSE:
            Initialize class instance
        ARGUMENTS:
            filename (string):  Name of the file containing the data to process (must end with 'residuals.dat')
        RETURNS:
            A initialized instance of CorrModel
        EXCEPTION SAFETY:
            Raises a CorrModelError instance if the arguments are of incorrect type or if data is not readable.
        EXAMPLES:
            model = CorrModel("my_fit_residuals.dat")
        """
        # check parameters' types
        if not (type(filename) == str):
            raise CorrDataError(self.__init__, 'Incorrect type of the parameter "filename". Could not generate instance')
        
        # check parameters' consistency
        try:
            assert filename[-13:] == 'residuals.dat'
        except AssertionError:
            raise CorrDataError(self.__init__, 'Incorrect type of the parameters. Could not generate instance')
        
        # read model
        try:
            self._model = np.genfromtxt(filename, dtype=[('index', int),
             ('pi', float),
             ('sigma', float),
             ('z', float),
             ('model', float),
             ('data', float),
             ('error', float)], usecols=(0, 1, 2, 3, 7, 8, 9))
        except IOError as ioerror:
            raise CorrDataError(self.__init__, str(ioerror).split(']')[-1])

        # format model into matrix
        self._formatData()

    def _formatData(self):
        """
        Formats current data into operable matrixes.
        
        FUNCTION: CorrModel._formatData
        TYPE: Private (to be accessed only from class member functions)
        PURPOSE:
            Formats current data into operable matrixes. Formatted matrixes are stored as new
            instance members and are not linked with the original arrays.
        EXAMPLES:
            self._formatData()
        """
        self._index_mat = np.copy(self._model['index'])
        self._model_mat = np.copy(self._model['model'])
        self._data_mat = np.copy(self._model['data'])
        self._grid_pi_mat = np.copy(self._model['pi'])
        self._grid_sigma_mat = np.copy(self._model['sigma'])
        self._grid_z_mat = np.copy(self._model['z'])

    def computeTransformationMatrix(self, new_pi, new_sigma, keep_matrix = False):
        """
        Compute the transformation matrix from the model bins to the given bins.
        
        FUNCTION: CorrModel.computeTransformationMatrix
        TYPE: Public (deprecated)
        PURPOSE:
            Compute the transformation matrix from the model bins to the specified bins. The bins must be
            wider than the original bins. Upon options may store the resulting matrix as a instance
            attribute. Previous similar instances are deleted.
        ARGUMENTS:
            new_pi (np.ndarray):    An array specifying the limits of the parallel separation bins
            new_sigma (np.ndarray): An array specifying the limits of the perpendicular separation bins
        KEYWORD ARGUMENTS:
            keep_matrix (boolean):  If True, keeps the resulting transformation matrix as a private instance
                                    attribute -- Default: False
        RETURNS:
            The transformation matrix between the model bins to the specified bins
        EXCEPTION SAFETY:
            Raises a CorrModelError instance if the parameters don't have the correct type or if the
            specified bins are smaller than the originals.
        EXAMPLES:
            model.computeTransformatiomMatrix(np.arange(-80, 80 + 4, 4), np.arange(0, 80+4, 4))
            model.computeTransformatiomMatrix(np.arange(-80, 80 + 4, 4), np.arange(0, 80+4, 4), keep_matrix=True)
            model.computeTransformatiomMatrix(np.arange(-80, 80 + 4, 4), np.arange(0, 80+4, 4), keep_matrix=False)
        """
        # check parameters' types
        if not (isinstance(new_pi, np.ndarray)):
            raise CorrModelError(self.computeTransformationMatrix, 'Incorrect type of the parameter "new_pi".')
        if not isinstance(new_sigma, np.ndarray):
            raise CorrModelError(self.computeTransformationMatrix, 'Incorrect type of the parameter "new_sigma".')
        if not (type(keep_matrix) == bool):
            raise CorrModelError(self.computeTransformationMatrix, 'Incorrect type of the parameter "keep_matrix".')

        # check parameters' consistency
        try:
            assert new_pi.size * new_sigma.size <= np.amax(self._index_mat)
        except AssertionError:
            raise CorrModelError(self.computeTransformationMatrix, 'Given bins are smaller than the originals.')
    
        # delete previous transformation instances if existent
        if hasattr(self, '_transformatiom_matrix'):
            del self._transformatiom_matrix
        
        transformation_matrix = np.zeros((self._model_mat.size, (new_pi.size - 1) * (new_sigma.size - 1)))
        
        # compute the overall relation between old and new bins
        k_conv = {}
        for k in range(0, self._grid_pi_mat.size):
            k_pi_new = 0
            try:
                while not (new_pi[k_pi_new] <= self._grid_pi_mat[k] and self._grid_pi_mat[k] <= new_pi[k_pi_new + 1]):
                    k_pi_new += 1
                    assert k_pi_new < new_pi.size - 1
            except AssertionError:
                continue
            
            k_sigma_new = 0
            try:
                while not (new_sigma[k_sigma_new] <= self._grid_sigma_mat[k] and self._grid_pi_mat[k] <= new_sigma[k_sigma_new + 1]):
                    k_sigma_new += 1
                    assert k_sigma_new < new_sigma.size - 1
            except AssertionError:
                continue
            
            k_conv[k] = k_pi_new * (new_sigma.size - 1) + k_sigma_new
                
        # then fill the transformation matrix
        for old, new in k_conv.items():
            transformation_matrix[old, new] = 1.0

        # keep transformation instances
        if keep_matrix:
            self._transformatiom_matrix = np.copy(transformation_matrix)
        return transformation_matrix

    def rebinModel(self, new_pi, new_sigma, keep_results = False):
        """
        Rebins the model to the specified binning
        
        FUNCTION: CorrModel.rebinModel
        TYPE: Public
        PURPOSE:
            Rebins the model to the specified binning. The bins must be
            wider than the original bins. The binning is preformed by averaging
            all the values of the original bin that fall into the new bin
            Upon options the method may store the resulting matrix as instance attributes.
            Previous similar instances are deleted.
        
        ARGUMENTS:
            new_pi (np.ndarray):    An array specifying the limits of the parallel separation bins
            new_sigma (np.ndarray): An array specifying the limits of the perpendicular separation bins
        KEYWORD ARGUMENTS:
            keep_results (boolean): If True, keeps the resulting rebinned matrixes as private instances 
                                    attributes -- Default: False
        RETURNS:
            The rebinned matrixes. The order is model_mat_new, data_mat_new, grid_pi_mat_new, 
            grid_sigma_mat_new, grid_z_mat_new, index_mat_new
        EXCEPTION SAFETY:
            Raises a CorrModelError instance if the parameters don't have the correct type or if the specified
            bins are smaller than the originals.
        EXAMPLES:
            model_mat_new, data_mat_new, grid_pi_mat_new,
                grid_sigma_mat_new, grid_z_mat_new, index_mat_new = model.rebinModel(pi, sigma)
            model_mat_new, data_mat_new, grid_pi_mat_new,
                grid_sigma_mat_new, grid_z_mat_new, index_mat_new = model.rebinModel(pi, sigma, keep_results=True)
            model_mat_new, data_mat_new, grid_pi_mat_new,
                grid_sigma_mat_new, grid_z_mat_new, index_mat_new = model.rebinModel(pi, sigma, keep_results=False)
        """
        # check parameters' types
        if not (isinstance(new_pi, np.ndarray)):
            raise CorrModelError(self.rebinModel, 'Incorrect type of the parameter "new_pi".')
        if not isinstance(new_sigma, np.ndarray):
            raise CorrModelError(self.rebinModel, 'Incorrect type of the parameter "new_sigma".')
        if not (type(keep_results) == bool):
            raise CorrModelError(self.rebinModel, 'Incorrect type of the parameter "keep_results".')
    
        # delele previous rebinned instances if present
        if hasattr(self, '_model_mat_new'):
            del self._model_mat_new
        if hasattr(self, '_data_mat_new'):
            del self._data_mat_new
        if hasattr(self, '_grid_pi_mat_new'):
            del self._grid_pi_mat_new
        if hasattr(self, '_grid_sigma_mat_new'):
            del self._grid_sigma_mat_new
        if hasattr(self, '_grid_z_mat_new'):
            del self._grid_z_mat_new
        
        # initialize lists
        index_mat_new = []
        model_mat_new = []
        data_mat_new = []
        grid_pi_mat_new = []
        grid_sigma_mat_new = []
        grid_z_mat_new = []

        # loop over new bins
        for pi_index in range(new_pi.size - 1):
            for sigma_index in range(new_sigma.size - 1):

                # initialize variables
                counts_new = 0.0
                model_new = 0.0
                data_new = 0.0
                grid_pi_new = 0.0
                grid_sigma_new = 0.0
                grid_z_new = 0.0
                    
                # loop over old bins
                for (model, data, grid_pi, grid_sigma, grid_z) in zip(self._model_mat, self._data_mat, self._grid_pi_mat,
                                                                      self._grid_sigma_mat, self._grid_z_mat):
                    # check if old bin falls inside the new one
                    if (grid_pi >= new_pi[pi_index] and grid_pi <= new_pi[pi_index + 1] and grid_sigma >= new_sigma[sigma_index]
                        and grid_sigma <= new_sigma[sigma_index + 1]):
                        counts_new += 1.0
                        model_new += model
                        data_new += data
                        grid_pi_new += grid_pi
                        grid_sigma_new += grid_sigma
                        grid_z_new += grid_z
            
                # normalize and add to list
                if counts_new != 0.0:
                    index_mat_new.append(pi_index*(new_sigma.size - 1) + sigma_index)
                    model_mat_new.append(model_new/counts_new)
                    data_mat_new.append(data_new/counts_new)
                    grid_pi_mat_new.append(grid_pi_new/counts_new)
                    grid_sigma_mat_new.append(grid_sigma_new/counts_new)
                    grid_z_mat_new.append(grid_z/counts_new)

        # recast list to ndarrays
        index_mat_new = np.array(index_mat_new)
        model_mat_new = np.array(model_mat_new)
        data_mat_new = np.array(data_mat_new)
        grid_pi_mat_new = np.array(grid_pi_mat_new)
        grid_sigma_mat_new = np.array(grid_sigma_mat_new)
        grid_z_mat_new = np.array(grid_z_mat_new)
        
        # keep rebinned instances
        if keep_results:
            self._index_mat_new = np.copy(index_mat_new)
            self._model_mat_new = np.copy(model_mat_new)
            self._data_mat_new = np.copy(data_mat_new)
            self._grid_pi_mat_new = np.copy(grid_pi_mat_new)
            self._grid_sigma_mat_new = np.copy(grid_sigma_mat_new)
            self._grid_z_mat_new = np.copy(grid_z_mat_new)
        
        return (model_mat_new, data_mat_new, grid_pi_mat_new, grid_sigma_mat_new, grid_z_mat_new, index_mat_new)

    def whichBins(self, sigma_min, sigma_max, subset='all', rebinned = False):
        """
        Determines which bins have perpedicular separations between sigma_min and sigma_max
        
        FUNCTION: CorrModel.whichBins
        TYPE: Public
        PURPOSE:
            Determines which bins have perpedicular separations between sigma_min and sigma_max.
            Bins with perpendicular separations equal to sigma_min are included and bins with
            perpendicular separations equal to sigma_max are excluded. Upon options only bins
            with positive or negative values of pi are included.
        ARGUMENTS:
            sigma_min (float): Minimum value of perpendicular separation to include a bin in the
                               return list
            sigma_max (float): Maximum value of perpendicular separation to include a bin in the
                               return list.
        KEYWORD ARGUMENTS:
            subset (string):   A string specifying whether or not there is an additional constrain
                               on the value of the parallel separation. It can have the values 
                               "pos" (includes only bins with positive or zero parallel separations),
                               "neg" (includes only bins with negative or zero parallel separations),
                               or "all" (no additional constrain) -- Default: "all"
            rebinned (bool):   If True, the rebinned matrixes will be considered except. If the
                               rebinned matrixes do not contain grid information, then this flag
                               is ignored. -- Default: False
        RETURNS: a np.where output with the position of the selected bins
        EXAMPLES:
            pos = model.whichBins(1.0, 3.0)
            pos = model.whichBins(1.0, 3.0, rebinned=True)
            pos = model.whichBins(1.0, 3.0, subset="neg")
            
        """
        # check parameters' types
        if not (type(sigma_min) == float or isinstance(sigma_min, np.float64)):
            raise CorrModelError(self.whichBins, 'Incorrect type of the parameter "sigma_min".')
        if not (type(sigma_max) == float or isinstance(sigma_max, np.float64)):
            raise CorrModelError(self.whichBins, 'Incorrect type of the parameter "sigma_max".')
        if not (type(subset) == str):
            raise CorrModelError(self.whichBins, 'Incorrect type of the parameter "subset".')
        if not (subset == "pos" or subset == "neg" or subset == "all"):
            raise CorrModelError(self.whichBins, 'Incorrect type of the parameter "subset".')
        if not (type(rebinned) == bool):
            raise CorrModelError(self.whichBins, 'Incorrect type of the parameter "rebinned".')
        
        # check parameters consistency
        try:
            assert sigma_max > sigma_min
        except AssertionError:
            raise CorrModelError(self.whichBins, 'sigma_max is lower than sigma_min')

        if rebinned:
            if hasattr(self, '_grid_sigma_mat_new') and hasattr(self, '_grid_pi_mat_new'):
                if subset == "all":
                    return np.where((self._grid_sigma_mat_new >= sigma_min) & (self._grid_sigma_mat_new < sigma_max))
                elif subset == "pos":
                    return np.where((self._grid_sigma_mat_new >= sigma_min) & (self._grid_sigma_mat_new < sigma_max) & (self._grid_pi_mat_new >= 0))
                else:
                    return np.where((self._grid_sigma_mat_new >= sigma_min) & (self._grid_sigma_mat_new < sigma_max) & (self._grid_pi_mat_new <= 0))
        if subset == "all":
            return np.where((self._grid_sigma_mat >= sigma_min) & (self._grid_sigma_mat < sigma_max))
        elif subset == "pos":
            return np.where((self._grid_sigma_mat >= sigma_min) & (self._grid_sigma_mat < sigma_max) & (self._grid_pi_mat >= 0))
        else:
            return np.where((self._grid_sigma_mat >= sigma_min) & (self._grid_sigma_mat < sigma_max) & (self._grid_pi_mat <= 0))

    def index_mat(self, rebinned = False):
        """
        Returns a copy of _index_mat
        
        FUNCTION: CorrModel.index_mat
        TYPE: Access
        PURPOSE: Returns a copy of _index_mat
        KEYWORD ARGUMENTS:
            rebinned: if True, returns a copy of _index_mat_new instead. If _index_mat_new does not exist,
                      then this flag is ignored
        RETURNS: A copy of _model_mat
        EXAMPLES:
            model_mat = model.index_mat()
            model_mat = model.index_mat(rebinned=True)
        """
        if rebinned:
            if hasattr(self, '_index_mat_new'):
                return np.copy(self._index_mat_new)
        return np.copy(self._index_mat)

    def grid_pi_mat(self, rebinned = False):
        """
        Returns a copy of _grid_pi_mat
            
        FUNCTION: CorrModel.grid_pi_mat
        TYPE: Access
        PURPOSE: Returns a copy of _grid_pi_mat
        KEYWORD ARGUMENTS:
            rebinned: if True, returns a copy of _grid_pi_mat_new instead. If _grid_pi_mat_new does
                      not exist, then this flag is ignored
        RETURNS: A copy of _grid_pi_mat
        EXAMPLES:
            grid_pi_mat = model.grid_pi_mat()
            grid_pi_mat = model.grid_pi_mat(rebinned=True)
        """
        if rebinned:
            if hasattr(self, '_grid_pi_mat_new'):
                return np.copy(self._grid_pi_mat_new)
        return np.copy(self._grid_pi_mat)

    def grid_sigma_mat(self, rebinned = False):
        """
        Returns a copy of _grid_sigma_mat
        
        FUNCTION: CorrModel.grid_sigma_mat
        TYPE: Access
        PURPOSE: Returns a copy of _grid_sigma_mat
        KEYWORD ARGUMENTS:
        rebinned: if True, returns a copy of _grid_sigma_mat_new instead. If _grid_sigma_mat_new does
        not exist, then this flag is ignored
        RETURNS: A copy of _grid_sigma_mat
        EXAMPLES:
        grid_sigma_mat = model.grid_sigma_mat()
        grid_sigma_mat = model.grid_sigma_mat(rebinned=True)
        """
        if rebinned:
            if hasattr(self, '_grid_sigma_mat_new'):
                return np.copy(self._grid_sigma_mat_new)
        return np.copy(self._grid_sigma_mat)

    def model_mat(self, rebinned = False):
        """
        Returns a copy of _model_mat
        
        FUNCTION: CorrModel.model_mat
        TYPE: Access
        PURPOSE: Returns a copy of _model_mat
        KEYWORD ARGUMENTS:
        rebinned: if True, returns a copy of _model_mat_new instead. If _model_mat_new does not exist,
        then this flag is ignored
        RETURNS: A copy of _model_mat
        EXAMPLES:
        model_mat = model.model_mat()
        model_mat = model.model_mat(rebinned=True)
        """
        if rebinned:
            if hasattr(self, '_model_mat_new'):
                return np.copy(self._model_mat_new)
        return np.copy(self._model_mat)


class CorrModelError(Exception):
    """
    CorrModel Exception
    
    CLASS: CorrMOdelError
    PURPOSE: CorrModel Exception
    PUBLIC FUNCTIONS:
        __init__(filename, pi, sigma)
        __str__()
    PRIVATE VARIABLES (should not be accessed outside the class body):
        _method (CorrData method): Mehtod of CorrModel that produced the error
        _message (string):         Error message
    """

    def __init__(self, method, message):
        """
        Initialize class instance
        
        FUNCTION: CorrModelError.__init__
        TYPE: Constructor, public
        PURPOSE: Initialize class instance
        ARGUMENTS:
            method (CorrData method):  Mehtod of CorrModel that produced the error
            message (string):          The error message
        RETURNS:
            A initialized instance of CorrDataError
        EXAMPLES:
            error = CorrModelError("this is an error")
        """
        self._method = method.__name__
        self._message = message

    def __str__(self):
        """
        Returns a printable representation of the error message
        
        FUNCTION: CorrModelError.__str__
        TYPE: Public
        PURPOSE: Returns a printable representation of the error message
        RETURNS:
            A printable representation of the error message
        EXAMPLES:
            print CorrModelError("this is a warning")
        """
        return 'In method {method}: {message}'.format(method=self._method, message=repr(self._message))


class CorrelationProcessError(Exception):
    """
    Handles exceptions caused by the functions in the module CorrelationProcess.
    
    CLASS: CorrelationProcessError
    PURPOSE:
        Handles exceptions caused by the functions in the module CorrelationProcess.
        The errors caused inside the classes of this module have their own Exception
    PUBLIC FUNCTIONS:
    __init__(self, filename, pi, sigma)
    __str__(self)
    PRIVATE VARIABLES (should not be accessed outside the class body):
    _method (CorrData method): Mehtod that produced the error
    _message (string):         Error message
    """

    def __init__(self, function, message):
        """
        Initialize class instance
        
        FUNCTION: CorrDataError.__init__
        TYPE: Constructor, public
        PURPOSE: Initialize class instance
        ARGUMENTS:
        method (CorrData method):  Function that produced the error
        message (string):          The error message
        RETURNS:
        A initialized instance of CorrDataError
        EXAMPLES:
        error = CorrDataError("this is an error")
        """
        self._function = function.__name__
        self._message = message

    def __str__(self):
        """
        Returns a printable representation of the error message
        
        FUNCTION: CorrDataWArning.__str__
        TYPE: Public
        PURPOSE: Returns a printable representation of the error message
        RETURNS:
        A printable representation of the error message
        EXAMPLES:
        print CorrDataError("this is a warning")
        """
        return 'In function {function}: {message}'.format(function=self._function, message=repr(self._message))

def invCovMatFromPlate(plate_num):
    """
    Reads the covariance matrix in a specific plate and returns its inverse
    
    FUNCTION: invCovMatFromPlate
    TYPE: Regular function
    PURPOSE:
        Reads the covariance matrix in a specific plate and returns its inverse. Whenever
        there is no info from one of the bins (for example if there are no pairs that
        contribute to bin 0), then this bin is not considered when computing the inverse
        of the covariance matrix.
        
        The covariance matrix file 
    
    """
    # TODO: fill function
    return

def plot(data_list, save_to, fmt_list = "k.", model_list=[], fmt_model_list = [], sigma_bins = None, contour = False, plot_rebinned_list = False, plot_model_rebinned_list = False, labels_list = None, labels_model_list = None, shifts_list = None, save_extension = 'eps', base_fig_name = 'cross_correlation', rmin_list= 10.0, smooth = True, plot_separated_errors = False, error_pos_list = []):
    """
    Plots the cross-correlation
    
    FUNCTION: plot
    TYPE: Regular function
    PURPOSE:
        Plots the cross-correlation against parallel separation in different perpendicular 
        separation bins. If a list of sigma bins are not specified, then the sigma bins are
        taken from the sigma_bins in the first dataset. If contour is set to True, then it 
        plots color-coded cross-correlation contours against parallel and perpendicular
        separations. This function assumes that data and model instances have the same binning
        independently of whether or not they are rebinned. Unexpected behaviour might occur if
        this condition is not met.
        
    ARGUMENTS:
        data_list (CorrData, list of CorrData, 
            or tuple of CorrData):               Data to plot. The format is either a 
                                                 single CorrData instance or a list of 
                                                 CorrData instances. If contour is set
                                                 to True, then it has to be a single
                                                 CorrData instance.
        save_to (string):                        Directory where plots will be saved.
    KEYWORD_ARGUMENTS:
        fmt_list (string, list of strings,
            or tuple of strings):                Format in whih to plot the different
                                                 datsets. Its number of elements must be
                                                 equal to the number of elements in
                                                 data_list. Each element must contain a
                                                 valid matplotlib-format string. Ignored
                                                 if contour is set to True. -- Default: "ko"
        model_list (CorrModel, list of CorrModel,
            or tuple of CorrModel):              Models to plot. The format is either a
                                                 single CorrModel instance or a list of
                                                 CorrModel instances. If contour is set 
                                                 to True, then it has to be a single
                                                 CorrModel instance.
        fmt_model_list (string, list of strings,
            or tuple of strings):                Format in whih to plot the different
                                                 models. Its number of elements must be
                                                 equal to the number of elements in
                                                 model_list. Each element must contain a
                                                 valid matplotlib-format string. Ignored 
                                                 if contour is set to True.
        sigma_bins (np.ndarray):                 Bins in parallel separation in which to
                                                 plot the cross-correlation. If None, then
                                                 the binning will be taken from the first
                                                 dataset -- Default: None
        contour (bool):                          If True, plots the contour plots instead
                                                 of plots in different sigma bins, sigma_bins
                                                 is ignored, and only one dataset and one model
                                                 are allowed. Formats (fmt_list and fmt_model_list)
                                                 are also ignored. plot_rebinned_list and
                                                 plot_model_rebinned_list also have to contain a 
                                                 single elements. Labels and shifts, if present, 
                                                 are ignored. rmin_list is ignored -- Default: False
        plot_rebinned_list (bool, list of bool,
            tuple of bool):                      If True, plots the rebinned data of the
                                                 dataset. If a single value is passed for 
                                                 multiple datasets, then this value will be
                                                 used for all of them. Otherwise there must be
                                                 as many values as datasets are provided
                                                 If the dataset has no rebinned data, the flag
                                                 is ignored. -- Default: False
        plot_model_rebinned_list (bool,
            list of bool, tuple of bool):        If True, plots the rebinned arrays of the
                                                 model. If a single value is passed for
                                                 multiple models, then this value will be
                                                 used for all of them. Otherwise there must be
                                                 as many values as models are provided
                                                 If the model has no rebinned data, the flag
                                                 is ignored. Ignored if contour is set to True.
                                                 -- Default: False
        labels_list (None, string, list of
            strings, or tuple of strings):       Name of the different datasets. Its number of
                                                 elements must be equal to the number of elements 
                                                 in data_list. Otherwise it has to be None, and no
                                                 labels will be displayed on the plots.
        labels_model_list (None, string, 
            list of strings, or tuple of 
            strings):                            Name of the different models. Its number of
                                                 elements must be equal to the number of elements
                                                 in model_list. Otherwise it has to be None, and no
                                                 labels will be displayed on the plots. Ignored if 
                                                 contour is set to True.
        shifts_list (None, float, list of
            floats, or tuple of floats):         Shifts to be applied to the different datasets.
                                                 Its number of elements must be equal to the number 
                                                 of elements in data_list. Otherwise it has to be 
                                                 None, and no shifts will be aplpied to the plots.
                                                 Ignored if contour is set to True.
        save_extension (string):                 Image extension of the files (eps, png, ...)
                                                 --- Default: "eps"
        base_fig_name (string):                  Image base name. Full name appends '_sigma_bin#.format',
                                                 where # is replaced by the corresponding bin number, 
                                                 and format is replaced by the value stored in 
                                                 save_extension. If contour is set to True, then full 
                                                 name appends '_contour.format' instead. 
                                                 --- Default: "cross_correlation"
        rmin_list (float, int, list of floats
            or ints, tuple of floats or ints):   Minimum distances (in Mph/h) considered by the fitting
                                                 models. Its number of elements must be equal to the
                                                 number of  elements in model_list. Otherwise it can
                                                 only have 1  element, which will be considered for all
                                                 the models. All values must be positive. Ignored if
                                                 contour is set to True. --- Default: 10.0
        smooth (bool):                           If True, averages the datapoints at large distances.
                                                 For 16 < r <= 32 the average is performed with the 
                                                 inmediately adjacent bins, and for 32 < r the average 
                                                 is performed with the two adjacent bins. Otherwise does
                                                 nothing. Ignored if contour is set to False.
                                                 --- Default: True
        plot_separated_errors (bool):            If True, plots the average errors outside the plot chart
                                                 at the positions specified by error_pos_list. The datapoints
                                                 are plotted without errorbars. Otherwise does nothing. 
                                                 Ignored if contour is set to True. --- Default: False
        error_pos_list (float, list of floats or
            tuple of floats):                    Position to plot the average errorbars relative to the 
                                                 axis size. Its number of elements must be equal to the
                                                 number of elements in data_list. All values must be between
                                                 0.0 and 1.0. Ignored if contour is set to True or if 
                                                 plot_separated_errors is set to False. --- Default: []
     EXCEPTION SAFETY:
        Raises a CorrelationProcessError instance if the arguments are of incorrect type,
        or arguments are not consistent. Assumes formats are given in valid matplotlib-format
        strings.
    EXAMPLES:
        plot(data, "./")
        plot(data, "./", fmt_list="k.", sigma_bins=sigma, plot_rebinned_list=False, model_list = model, fmt_model_list = "k-", plot_model_rebinned_list=False, base_fig_name="cross_correlation_not_rebinned", rmin=5)
        plot(data, "./", fmt_list="k.", sigma_bins=sigma_new, plot_rebinned_list=True, model_list = model, fmt_model_list = "k-", plot_model_rebinned_list = True, rmin=5)
        plot(data, "./", model_list=model, plot_rebinned_list=False, plot_model_rebinned_list=False, contour=True)
    """
    # check parameters' types
    if not (isinstance(data_list, CorrData) or type(data_list) == list or type(data_list) == tuple):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "data_list".')
    if type(data_list) == list or type(data_list) == tuple:
        for item in data_list:
            if not (isinstance(item, CorrData)):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "data_list".')

    if not (type(save_to) == str):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "save_to".')

    if not (type(fmt_list) == str or type(fmt_list) == list or type(fmt_list) == tuple or contour):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "fmt_list".')
    if (type(fmt_list) == list or type(fmt_list) == tuple) and (not contour):
        for item in fmt_list:
            if not (type(item) == str):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "fmt_list".')
    
    if not (isinstance(model_list, CorrModel) or type(model_list) == list or type(model_list) == tuple or contour):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "model_list".')
    if (type(model_list) == list or type(model_list) == tuple) and (not contour):
        for item in model_list:
            if not (isinstance(item, CorrModel)):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "model_list".')
    
    if not (type(fmt_model_list) == str or type(fmt_model_list) == list or type(fmt_model_list) == tuple or contour):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "fmt_model_list".')
    if (type(fmt_model_list) == list or type(fmt_model_list) == tuple) and (not contour):
        for item in fmt_model_list:
            if not (type(item) == str):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "fmt_model_list".')
    
    if not (sigma_bins == None or isinstance(sigma_bins, np.ndarray)):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "sigma_bins".')

    if not (type(contour) == bool):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "contour".')

    if not (type(plot_rebinned_list) == bool or type(plot_rebinned_list) == list or type(plot_rebinned_list) == tuple):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "plot_rebinned_list".')
    if type(plot_rebinned_list) == list or type(plot_rebinned_list) == tuple:
        for item in plot_rebinned_list:
            if not (type(item) == bool):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "plot_rebinned_list".')
    
    if not (type(plot_model_rebinned_list) == bool or type(plot_model_rebinned_list) == list or type(plot_model_rebinned_list) == tuple):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "plot_model_rebinned_list".')
    if type(plot_model_rebinned_list) == list or type(plot_model_rebinned_list) == tuple:
        for item in plot_model_rebinned_list:
            if not (type(item) == bool):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "plot_model_rebinned_list".')

    if not (labels_list == None or type(labels_list) == str or type(labels_list) == list or type(labels_list) == tuple):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "labels_list".')
    if type(labels_list) == list or type(labels_list) == tuple:
        for item in labels_list:
            if not (type(item) == str):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "labels_list".')

    if not (labels_model_list == None or type(labels_model_list) == str or type(labels_model_list) == list
            or type(labels_model_list) == tuple or contour):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "labels_model_list".')
    if type(labels_model_list) == list or type(labels_model_list) == tuple:
        for item in labels_list:
            if not (type(item) == str or contour):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "labels_model_list.')

    if not (shifts_list == None or type(shifts_list) == float or type(shifts_list) == list or type(shifts_list) == tuple or contour):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "shifts_list".')
    if type(shifts_list) == list or type(shifts_list) == tuple:
        for item in shifts_list:
            if not (type(item) == float or contour):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "shifts_list".')

    if not (type(save_extension) == str):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "save_extension".')

    if not (type(base_fig_name) == str):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "base_fig_name".')

    if not (type(rmin_list) == float or type(rmin_list) == int or type(rmin_list) == list or type(rmin_list) == tuple or contour):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "rmin_list".')
    if type(rmin_list) == list or type(rmin_list) == tuple:
        for item in rmin_list:
            if not (type(item) == int or type(item) == float or contour):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "rmin_list".')
            if not (item >= 0.0 or contour):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "rmin_list".')
    else:
        if not (rmin_list >= 0.0 or contour):
            raise CorrelationProcessError(plot, 'Incorrect type of the parameter "rmin_list".')

    if not (type(smooth) == bool or (not contour)):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "smooth".')

    if not (type(plot_separated_errors) == bool or contour):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "plot_separated_errors".')

    if not (type(error_pos_list) == float or type(error_pos_list) == list or type(error_pos_list) == tuple or contour or (not plot_separated_errors)):
        raise CorrelationProcessError(plot, 'Incorrect type of the parameter "error_pos_list".')
    if (type(error_pos_list) == list or type(error_pos_list) == tuple):
        for item in error_pos_list:
            if not (type(item) == float or contour or (not plot_separated_errors)):
                raise CorrelationProcessError(plot, 'Incorrect type of the parameter "error_pos_list".')

    # check parameters' consistency
    try:
        if contour:
            # convert all relevant parameters to elements if necessary
            if type(data_list) == list or type(data_list) == tuple:
                if not (len(data_list) == 1):
                    raise CorrelationProcessError(plot, 'Parameter "data_list" is not consistent with the requirements.')
                data_list = data_list[0]
            if type(plot_rebinned_list) == list or type(plot_rebinned_list) == tuple:
                if not (len(plot_rebinned_list) == 1):
                    raise CorrelationProcessError(plot, 'Parameter "plot_rebinned_list" is not consistent with the requirements.')
                plot_rebinned_list == plot_rebinned_list[0]
            if type(model_list) == list or type(model_list) == tuple:
                if not (len(model_list) == 1):
                    raise CorrelationProcessError(plot, 'Parameter "model_list" is not consistent with the requirements.')
                shifts_list == shifts_list[0]
            if type(plot_model_rebinned_list) == list or type(plot_model_rebinned_list) == tuple:
                if not (len(plot_model_rebinned_list) == 1):
                    raise CorrelationProcessError(plot, 'Parameter "plot_model_rebinned_list" is not consistent with the requirements.')
                plot_model_rebinned_list == plot_model_rebinned_list[0]

        else:
            # convert all relevant parameters to one element lists if necessary
            if isinstance(data_list, CorrData):
                data_list = [data_list]
            
            if type(fmt_list) == str:
                fmt_list = [fmt_list]

            if isinstance(model_list, CorrModel):
                model_list = [model_list]

            if type(fmt_model_list) == str:
                fmt_model_list = [fmt_model_list]

            if type(plot_rebinned_list) == bool:
                plot_rebinned_list = [plot_rebinned_list]

            if type(plot_model_rebinned_list) == bool:
                plot_model_rebinned_list = [plot_model_rebinned_list]

            if type(labels_list) == str:
                labels_list = [labels_list]

            if type(labels_model_list) == str:
                labels_model_list = [labels_model_list]

            if type(shifts_list) == float:
                shifts_list = [shifts_list]
            
            if type(rmin_list) == int or type(rmin_list) == float:
                rmin_list = [float(rmin_list)]
            if type(rmin_list) == tuple or type(rmin_list) == list:
                rmin_list = [float(item) for item in rmin_list]

            if type(error_pos_list) == float and plot_separated_errors:
                error_pos_list = [error_pos_list]
    
            # check that all lists have the appropiate length and correct for it in special cases
            # (check parameters description)
            assert len(fmt_list) == 1 or len(fmt_list) == len(data_list)
            if len(fmt_list) == 1:
                fmt_list = [fmt_list[0]] * len(data_list)

            assert len(fmt_model_list) == 1 or len(fmt_model_list) == len(model_list)
            if len(fmt_model_list) == 1:
                fmt_model_list = [fmt_model_list[0]] * len(model_list)

            assert len(plot_rebinned_list) == 1 or len(plot_rebinned_list) == len(data_list)
            if len(plot_rebinned_list) == 1:
                plot_rebinned_list = [plot_rebinned_list[0]] * len(data_list)

            assert len(plot_model_rebinned_list) == 1 or len(plot_model_rebinned_list) == len(model_list)
            if len(plot_model_rebinned_list) == 1:
                plot_model_rebinned_list = [plot_model_rebinned_list[0]] * len(model_list)

            assert labels_list == None or len(labels_list) == 1 or len(labels_list) == len(data_list)
            if labels_list != None and len(labels_list) == 1:
                labels_list = [labels_list[0]] * len(data_list)

            assert labels_model_list == None or len(labels_model_list) == 1 or len(labels_model_list) == len(model_list)
            if labels_model_list != None and len(labels_model_list) == 1:
                labels_model_list = [labels_model_list[0]] * len(model_list)

            assert shifts_list == None or len(shifts_list) == 1 or len(shifts_list) == len(shifts_list)
            if shifts_list != None and len(shifts_list) == 1:
                shifts_list = [shifts_list[0]] * len(data_list)
            elif shifts_list == None:
                shifts_list = [0.0] * len(data_list)

            if sigma_bins == None:
                sigma_bins = data[0].sigma(rebinned=plot_rebinned_list[0])
                    
            assert len(rmin_list) == 1 or len(rmin_list) == len(model_list)
            if len(rmin_list) == 1:
                rmin_list = [rmin_list[0]] * len(model_list)

            if plot_separated_errors:
                assert len(error_pos_list) == len(data_list)

    except AssertionError:
        raise CorrelationProcessError(plot, 'Given parameters are not consistent.')

    if contour:
        # get pi and sigma limits from the CorrData instance
        pi_bins = data_list.pi(rebinned=plot_rebinned_list)
        sigma_bins = data_list.sigma(rebinned=plot_rebinned_list)

        # compute the middle point in the bins
        pi_mid_bins = np.array([(pi_bins[i]+pi_bins[i + 1])/2.0 for i in range(pi_bins.size - 1)])
        sigma_mid_bins = np.array([(sigma_bins[i]+sigma_bins[i + 1])/2.0 for i in range(sigma_bins.size - 1)])

        # compute the two-dimensional shape of the matrixes
        shape = (pi_mid_bins.size, sigma_mid_bins.size)

        # format the data and error matrixes to a two-dimensional array
        data_values = data_list.data_mat(rebinned=plot_rebinned_list)
        if not (shape[0]*shape[1] == data_values.size):
            raise CorrelationProcessError(plot, '"data" does not have the right number of elements, expected: {}, found: {}. If using the rebinning, check that all the relevant matrixes were stored'.format(shape[0]*shape[1], data_values.size))
        data_values = data_values.reshape(shape)
        error_values = data_list.error(rebinned=plot_rebinned_list)
        if not (shape[0]*shape[1] == error_values.size):
            raise CorrelationProcessError(plot, '"error" does not have the right number of elements, expected: {}, found: {}. If using the rebinning, check that all the relevant matrixes were stored'.format(shape[0]*shape[1], error_values.size))
        error_values = error_values.reshape(shape)

        # fill the voids in the model
        aux = 0
        model_values = []
        for (index, model) in zip(model_list.index_mat(rebinned=plot_model_rebinned_list), model_list.model_mat(rebinned=plot_model_rebinned_list)):
            while (aux < index):
                model_values.append(np.nan)
                aux += 1
            model_values.append(model)
            aux += 1
        while aux < shape[0]*shape[1]:
            model_values.append(np.nan)
            aux += 1

        # format the model matrix to a two-dimensional array
        model_values = np.array(model_values).reshape(shape)

        # smooth the datapoints
        if smooth:
            # average at large distances
            data_averaged = np.copy(data_values)
            for pi_index, pi in enumerate(pi_mid_bins):
                for sigma_index, sigma  in enumerate(sigma_mid_bins):
                    if np.isnan(data_values[pi_index][sigma_index]):
                        continue
                    r2 = pi*pi+sigma*sigma
                    # do nothing for r <= 16
                    if r2 <= 16.0*16.0:
                        pass
                    # for 16 < r <= 32 we average with the inmediately adjacent bins; weight the bins with 1/(error+0.05)
                    elif r2 <= 32.0*32.0:
                        v = 0.0
                        e = 0.0
                        for index1 in range(-1, 2):
                            for index2 in range(-1,2):
                                try:
                                    if (not np.isnan(data_values[pi_index + index1][sigma_index + index2])) and (not np.isnan(error_values[pi_index + index1][sigma_index + index2])):
                                        v += data_values[pi_index + index1][sigma_index + index2]/(error_values[pi_index + index1][sigma_index + index2]+0.05)
                                        e += 1.0/(error_values[pi_index + index1][sigma_index + index2]+0.05)
                                except IndexError:
                                    pass
                        if e > 0.0:
                            v /= e
                        if v != 0.0:
                            data_averaged[pi_index][sigma_index] = v
                    # for 32 < r we average with the two adjacent bins; weight the bins with 1/(error+0.05)
                    else:
                        v = 0.0
                        e = 0.0
                        for index1 in range(-2,3):
                            for index2 in range(-2,3):
                                try:
                                    if (not np.isnan(data_values[pi_index + index1][sigma_index + index2])) and (not np.isnan(error_values[pi_index + index1][sigma_index + index2])):
                                        v += data_values[pi_index + index1][sigma_index + index2]/(error_values[pi_index + index1][sigma_index + index2]+0.05)
                                        e += 1.0/(error_values[pi_index + index1][sigma_index + index2]+0.05)
                                except IndexError:
                                    pass
                        if e > 0.0:
                            v /= e
                        if v != 0.0:
                            data_averaged[pi_index][sigma_index] = v

        # figure settings
        cmap = plt.cm.get_cmap('CMRmap')
        num_colors = 40.0
        vmin = np.amin(data_values)
        vmax = np.amax(data_values)
        step = (vmax - vmin) / num_colors
        levels = np.arange(vmin, vmax + step, step)
        gs = gridspec.GridSpec(2, 3, width_ratios=[10, 10, 1], height_ratios=[2, 1])
        gs.update(bottom=0.2, wspace=0.05, hspace=0.08)
        fontsize = 32
        labelsize = 22
        labelsize2 = 18
        figsize=(16, 26)

        # plot the data
        fig = plt.figure(figsize=figsize)
        ax = fig.add_subplot(gs[0,0])
        #ax.set_xlabel('$\\sigma {\\rm \\left(h^{-1}Mpc\\right)}$', fontsize=fontsize)
        ax.set_ylabel('$\\pi {\\rm \\left(h^{-1}Mpc\\right)}$', fontsize=fontsize)
        ax.tick_params(axis='both', pad=10, labelsize=labelsize, width=2, length=6)
        if smooth:
            cs = ax.contourf(sigma_mid_bins, pi_mid_bins, data_averaged, levels, cmap=cmap, vmin=vmin, vmax=vmax, fontsize=labelsize)
        else:
            cs = ax.contourf(sigma_mid_bins, pi_mid_bins, data_values, levels, cmap=cmap, vmin=vmin, vmax=vmax, fontsize=labelsize)

        ax2 = fig.add_subplot(gs[0,1])
        #ax2.set_xlabel('$\\sigma {\\rm \\left(h^{-1}Mpc\\right)}$', fontsize=fontsize)
        ax2.tick_params(axis='x', pad=10, labelsize=labelsize, width=2, length=6)
        ax2.tick_params(axis='y', labelleft='off', width=2, length=6)
        cs2 = ax2.contourf(sigma_mid_bins, pi_mid_bins, model_values, levels, cmap=cmap, vmin=vmin, vmax=vmax, fontsize=labelsize)

        ax3 = fig.add_subplot(gs[0,2])
        cbar = fig.colorbar(cs, cax=ax3, format='%.2f')
        cbar.ax.tick_params(labelsize=labelsize2, width=2, length=6)


        ax4 = fig.add_subplot(gs[1,0])
        ax4.set_xlabel('$\\sigma {\\rm \\left(h^{-1}Mpc\\right)}$', fontsize=fontsize)
        ax4.set_ylabel('$\\pi {\\rm \\left(h^{-1}Mpc\\right)}$', fontsize=fontsize)
        ax4.tick_params(axis='both', pad=10, labelsize=labelsize, width=2, length=6)
        ax4.set_xlim(2, 42)
        ax4.set_ylim(-20, 20)
        if smooth:
            cs4 = ax4.contourf(sigma_mid_bins, pi_mid_bins, data_averaged, levels, cmap=cmap, vmin=vmin, vmax=vmax, fontsize=labelsize)
        else:
            cs4 = ax4.contourf(sigma_mid_bins, pi_mid_bins, data_values, levels, cmap=cmap, vmin=vmin, vmax=vmax, fontsize=labelsize)

        ax5 = fig.add_subplot(gs[1,1])
        ax5.set_xlabel('$\\sigma {\\rm \\left(h^{-1}Mpc\\right)}$', fontsize=fontsize)
        ax5.tick_params(axis='x', pad=10, labelsize=labelsize, width=2, length=6)
        ax5.tick_params(axis='y', labelleft='off', width=2, length=6)
        cs5 = ax5.contourf(sigma_mid_bins, pi_mid_bins, model_values, levels, cmap=cmap, vmin=vmin, vmax=vmax, fontsize=labelsize)
        ax5.set_xlim(2, 42)
        ax5.set_ylim(-20, 20)

        # save the plot
        fig.savefig('{}{}_contour.{}'.format(save_to, base_fig_name, save_extension))
        plt.close(fig)

    # plot the cross-correlation in different sigma bins
    else:
        # figure settings
        if plot_separated_errors:
            gs = gridspec.GridSpec(1, 2, width_ratios=[10,1])
            gs.update(left=0.2, bottom=0.2, wspace=0.01)
        else:
            gs = gridspec.GridSpec(1, 1)
            gs.update(left=0.2, bottom=0.2)
        fontsize = 32
        labelsize = 22
        figsize = (9, 7)
        
        for bin_num, sigma_min in enumerate(sigma_bins[:-1]):
            sigma_max = sigma_bins[bin_num + 1]
            print 'plotting sigma bin {}'.format(bin_num)
            pos_list = [ data.whichBins(sigma_min, sigma_max, rebinned=plot_rebinned) for data, plot_rebinned in zip(data_list, plot_rebinned_list) ]
            # check if the model is continuus or discontinuus in this region
            model_pos_list = []
            for model, plot_rebinned, rmin in zip(model_list, plot_model_rebinned_list, rmin_list):
                if sigma_max >= rmin:
                    model_pos_list.append([model.whichBins(sigma_min, sigma_max, rebinned=plot_rebinned, subset="all")])
                else:
                    model_pos_list.append([model.whichBins(sigma_min, sigma_max, rebinned=plot_rebinned, subset="pos") ,
                                           model.whichBins(sigma_min, sigma_max, rebinned=plot_rebinned, subset="neg")])
            
            # plot the data
            fig = plt.figure(figsize=figsize)
            ax = fig.add_subplot(gs[0])
            # if plot_separated_errors is set to True plot datapoints without errorbars and plot the errors at the specified positions
            if plot_separated_errors:
                if labels_list == None:
                    [ ax.plot(data.grid_pi_mat(rebinned=plot_rebinned)[pos] + shift, data.data_mat(rebinned=plot_rebinned)[pos], fmt) for data, fmt, plot_rebinned, pos, shift in zip(data_list, fmt_list, plot_rebinned_list, pos_list, shifts_list) ]
                else:
                    [ ax.plot(data.grid_pi_mat(rebinned=plot_rebinned)[pos] + shift, data.data_mat(rebinned=plot_rebinned)[pos], fmt, label=label) for data, fmt, plot_rebinned, label, pos, shift in zip(data_list, fmt_list, plot_rebinned_list, labels_list, pos_list, shifts_list) ]
                        
                # compute errors average and plot them at the specified positions
                mean_error_list = [np.sum(data.error(rebinned=plot_rebinned)[pos])/data.error(rebinned=plot_rebinned)[pos].size for data, plot_rebinned, pos in zip(data_list, plot_rebinned_list, pos_list)]
                ax2 = fig.add_subplot(gs[1])
                [ax2.errorbar(pos, 0.2, yerr=mean_error/(ax.get_ylim()[1]-ax.get_ylim()[0]), fmt=fmt, transform=ax2.transAxes) for mean_error, fmt, pos in zip(mean_error_list, fmt_list, error_pos_list)]
                ax2.tick_params(axis='both', bottom='off', left='off', top='off', right='off')
                ax2.axis('off')
                ax2.tick_params(axis='both', bottom='off', top='off', left='off', right='off', labelbottom='off', labeltop='off', labelleft='off', labelright='off')
                ax2.set_ylim(ax.get_ylim())
            
            # otherwise plot datapoints with their errorbars
            else:
                if labels_list == None:
                    [ ax.errorbar(data.grid_pi_mat(rebinned=plot_rebinned)[pos] + shift, data.data_mat(rebinned=plot_rebinned)[pos], yerr=data.error(rebinned=plot_rebinned)[pos], fmt=fmt) for data, fmt, plot_rebinned, pos, shift in zip(data_list, fmt_list, plot_rebinned_list, pos_list, shifts_list) ]
                else:
                    [ ax.errorbar(data.grid_pi_mat(rebinned=plot_rebinned)[pos] + shift, data.data_mat(rebinned=plot_rebinned)[pos], yerr=data.error(rebinned=plot_rebinned)[pos], fmt=fmt, label=label) for data, fmt, plot_rebinned, label, pos, shift in zip(data_list, fmt_list, plot_rebinned_list, labels_list, pos_list, shifts_list) ]
            # plot the model
            if labels_model_list == None:
                for model, fmt, plot_rebinned, model_pos in zip(model_list, fmt_model_list, plot_model_rebinned_list, model_pos_list):
                    [ax.plot(model.grid_pi_mat(rebinned=plot_rebinned)[model_pos_item], model.model_mat(rebinned=plot_rebinned)[model_pos_item], fmt) for model_pos_item in model_pos]
            else:
                for model, fmt, plot_rebinned, model_pos, label in zip(model_list, fmt_model_list, plot_model_rebinned_list, model_pos_list, labels_model_list):
                    ax.plot(model.grid_pi_mat(rebinned=plot_rebinned)[model_pos[0]], model.model_mat(rebinned=plot_rebinned)[model_pos[0]], fmt, label=label)
                    [ ax.plot(model.grid_pi_mat(rebinned=plot_rebinned)[model_pos_item], model.model_mat(rebinned=plot_rebinned)[model_pos_item], fmt) for model_pos_item in model_pos[1:] ]

            ax.set_xlabel('$\\pi\\,\\left(\\rm h^{-1}Mpc\\right)$', fontsize=fontsize)
            ax.set_ylabel('$\\xi\\left(\\pi, \\sigma\\right)$', fontsize=fontsize)
            ax.text(0.05, 0.05, '$' + str(sigma_min) + ' < \\sigma <' + str(sigma_max) + '$', fontsize=fontsize, transform=ax.transAxes)
            ax.tick_params(axis='both', pad=10, labelsize=labelsize)
            yticks = ax.yaxis.get_major_ticks()
            yticks[0].label1.set_visible(False)
            if labels_list != None:
                ax.legend(numpoints=1, loc=4)
            
            # save the plot
            fig.savefig('{}{}_sigma_bin_{}.{}'.format(save_to, base_fig_name, bin_num, save_extension))
            plt.close(fig)


def rebinIgnoringCovMat(data, pi, sigma):
    """
    Rebins the data to the specified binning ignoring the covariance matrix
    
    FUNCTION: rebinIgnoringCovMat
    TYPE: Regular function
    PURPOSE:
        Rebins the data to the specified binning ignoring the covariance matrix
        The rebinning is performed as follows
        
        The covariance matrix is rebinned as
        C_{new}^{-1} = S^{t} S,
        where S is the specified transformation matrix.
        
        The data is rebinned as
        data_{new} = C_{new} S^{t} data
    ARGUMENTS:
        data (CorrData):    Instance of CorrData containing the data to rebin
        pi (np.ndarray):    New binning for parallel
        sigma (np.ndarray): New binning for perpendicular separation
    RETURNS: The rebinned data matrix.
    EXAMPLES:
        data_mat_new = rebinIgnoringCovMat(data, np.array([-10, 10]), np.array([10, 20]))
    """
    # check parameters type
    if not (isinstance(data, CorrData)):
        raise CorrelationProcessError(rebinIgnoringCovMat, 'Incorrect type of the parameter "data".')
    if not (isinstance(pi, np.ndarray)):
        raise CorrelationProcessError(rebinIgnoringCovMat, 'Incorrect type of the parameter "pi".')
    if not (isinstance(sigma, np.ndarray)):
        raise CorrelationProcessError(rebinIgnoringCovMat, 'Incorrect type of the parameter "sigma".')


    data_mat = data.data_mat()

    # compute the transformation matrix
    transformation_matrix = data.computeTransformationMatrix(pi, sigma)

    # assume identity as original covariance matrix and rebin it
    inv_cov_mat_new = np.dot(transformation_matrix.transpose(), transformation_matrix)
    cov_mat_new = np.linalg.inv(inv_cov_mat_new)

    # rebin data
    data_mat_new = np.dot(cov_mat_new, np.dot(transformation_matrix.transpose(), data_mat))

    return data_mat_new


def showDocumentation(fnc):
    """
    Shows the documentation for the selected items(s)
    
    FUNCTION: showDocumentation
    TYPE: Regular function
    PURPOSE: 
        Shows the documentation for the selected items(s). Items may be classes, methods,
        or functions. If 'all' is passed, prints the documentation of all the classes,
        mehtods and functions. If 'module' is passed, prints the module documentation
    ARGUMENTS:
        fnc (list or tuple of objects, 
             objects, 'all' or 'module'): Function(s) the documentation of which is to 
                                          be printed
    EXAMPLES:
        showDocumentation(CorrData)
        showDocumentation(CorrData.rebinData)
        showDocumentation(showDocumentation)
        showDocumentation([CorrData, CorrData.rebinData, showDocumentation])
        showDocumentation((CorrData, corrData.rebinData, showDocumentation))
        showDocumentation("module")
        showDocumentation("all")
    """
    # check parameters' type
    if type(fnc) == tuple or type(fnc) == list:
        for item in fnc:
            if not (inspect.isfunction(item) or inspect.isclass(item) or inspect.ismethod(item)):
                raise CorrelationProcessError(showDocumentation, 'Incorrect type of the parameter "fnc".')
    elif type(fnc) == str:
        if not (fnc == 'all' or fnc == 'module'):
            raise CorrelationProcessError(showDocumentation, 'Incorrect type of the parameter "fnc".')
    else:
        if not (inspect.isfunction(fnc) or inspect.isclass(fnc) or inspect.ismethod(fnc)):
            raise CorrelationProcessError(showDocumentation, 'Incorrect type of the parameter "fnc".')

    # print the entire documentation
    if fnc == 'all':
        module = sys.modules[__name__]
        functions_list = inspect.getmembers(module, inspect.isfunction)
        for item in functions_list:
            print '\nDocumentation for {}:\n'.format(item[0])
            print trim(item[1].__doc__)
            print '\n'

        classes_list = inspect.getmembers(module, inspect.isclass)
        for class_name, class_object in classes_list:
            print '\nDocumentation for {}:\n'.format(class_name)
            print trim(class_object.__doc__)
            print '\n'
            methods_list = inspect.getmembers(class_object, inspect.ismethod)
            for item in methods_list:
                print '\nDocumentation for {}.{}:\n'.format(class_name, item[0])
                print trim(item[1].__doc__)
                print '\n'

    # print the module documentation
    elif fnc == 'module':
        module = sys.modules[__name__]
        print '\nDocumentation for module {}:\n'.format(module.__name__)
        print trim(module.__doc__)
        print '\n'
    
    # print the documentation for the selected classes, functions, and methods
    elif type(fnc) == tuple or type(fnc) == list:
        for item in fnc:
            if hasattr(item, 'im_class'):
                print '\nDocumentation for {}.{}:\n'.format(item.im_class.__name__, item.__name__)
            else:
                print '\nDocumentation for {}:\n'.format(item.__name__)
            print trim(item.__doc__)
            print '\n'

    else:
        if hasattr(fnc, 'im_class'):
            print '\nDocumentation for {}.{}:\n'.format(fnc.im_class.__name__, fnc.__name__)
        else:
            print '\nDocumentation for {}:\n'.format(fnc.__name__)
        print trim(fnc.__doc__)
        print '\n'


def trim(docstring):
    """
    Format the given docstring to be readable
    
    FUNCTION: showDocumentation
    TYPE: Regular function
    PURPOSE:
    Docstring processing tools will strip a uniform amount of indentation from the second 
    and further lines of the docstring, equal to the minimum indentation of all non-blank 
    lines after the first line. Any indentation in the first line of the docstring (i.e., 
    up to the first newline) is insignificant and removed except for a single indentation 
    block. Relative indentation of later lines in the docstring is retained. Blank lines 
    should be removed from the beginning and end of the docstring. 
    Adapted from https://www.python.org/dev/peps/pep-0257/
    ARGUMENTS:
        docstring (string): The docstring to be formattted
    EXAMPLES:
        trim(object.__doc__)
    """
    # check parameters' type
    if not (type(docstring) == str):
        raise CorrelationProcessError(trim, 'Incorrect type of the parameter "docstring".')
    
    if not docstring:
        return ''
    lines = docstring.expandtabs().splitlines()
    indent = sys.maxint
    for line in lines[1:]:
        stripped = line.lstrip()
        if stripped:
            indent = min(indent, len(line) - len(stripped))

    trimmed = [lines[0].strip()]
    if indent < sys.maxint:
        for line in lines[1:]:
            trimmed.append(line[indent:].rstrip())

    while trimmed and not trimmed[-1]:
        trimmed.pop()

    while trimmed and not trimmed[0]:
        trimmed.pop(0)

    return '    ' + '\n    '.join(trimmed)


def testRebinning(num_test_groups):
    """
    Test the rebinning performed by the functions CorrData.rebinData and rebinIgnoringCovMat
    
    FUNCTION: testRebinning
    TYPE: Test function
    PURPOSE:
        Test the rebinning performed by the functions CorrData.rebinData and rebinIgnoringCovMat.
        To do so, the function uses the data found in 'test#.data', 'test#.cov', and 'test#.grid'
        in folder 'test_rebinning/' (where # is an integer going from 1 to num_test_groups, both
        included). The function performs the rebinnings proposed in 'test#.rebin' and compares 
        the results against 'test#.sol'.
        
        The format of 'test#.data', 'test#.cov', and 'test#.grid' are the same as the 
        cross-correlation output files with the same extension. The file 'test#.grid' may or may
        not be missing.
        
        The files 'test#.rebin' specifies the tests to be applied to the group. It must contain 
        the following:
        - 1st line: Binning in parallel and perpendicular separations. The format is to have 'pi'
                    followed by the limits on the parallel separation, then have 'sigma' followed 
                    by the limits on the perpendicular separation. Separator between elements must
                    be a single white space. Example:
                        'pi -1.0 0.0 1.0 sigma 0.0 1.0 2.0'
        - rest of the lines: Name of the test, and the binning in parallel and perpendicular 
                             separation the data is to be rebinned to. The format is the same as 
                             the first line, preceded by the name of the test and a white space. 
                             The name of the test must be 'RI#' to test the function 
                             rebinIgnoringCovMat and 'R#' to test the function CorrData.rebinData. 
                             Examples:
                                 'RI1 pi -1.0 1.0 sigma 0.0 2.0' - to test rebinIgnoringCovMat
                                 'R1 pi -1.0 1.0 sigma 0.0 2.0' - to test CorrData.rebinData
        
        The file 'test#.sol' must contain the results of the proposed tests in the same order.
        The results of each test are a line starting with the name of the test, the resulting
        data matrix, and the resulting covariance matrix (the last one only if function 
        CorrData.rebinData is being tested). The format is to put the name followed by a white 
        space, then 'data' followed by the data matrix, then 'cov' followed by the covariance
        matrix elements printed by columns. Numbers must contain 4 decimal digits. Keep in mind 
        that lines must not end with a white space, and that no new line must be found at end of
        file. Examples:
            'RI2 data 52.5000 22.5000'
            'R2 data 30.1449 50.0489 cov 2.0017 -0.0450 -0.0450 1.5010'
            
        The function will write a 'test#.res' file with the result. If this file is identical
        to 'test#.sol', all the tests will have passed. Line-to-line differences show the test
        that have not passed. Note that function will consider only 4 decimal places in the
        comparison with the provided solution.
    ARGUMENTS:
        num_tests_groups (int): Number of tests groups to analyze. Must be at least 1.
    RETURNS: The rebinned data matrix.
    EXAMPLES:
        testRebinning(3)
    """
    # check parameters' type
    if not (type(num_test_groups) == int):
        raise CorrelationProcessError(testRebinning, 'Incorrect type of the parameter "num_test_groups".')

    print '\n\nTesting the functions CorrData.rebinData and rebinIgnoringCovMat.'
    print 'There are {} test groups specified\n'.format(num_test_groups)
    for test_group in range(1, num_test_groups + 1):
        # load binning informationfrom *.rebin file
        try:
            lines = open('test_rebinning/test{}.rebin'.format(test_group)).readlines()
        except IOError:
            raise CorrelationProcessError(testRebinning, 'missing test{}.rebin'.format(test_group))
        cols = lines[0].split()
        cols_index = 0
        if cols[cols_index] == 'pi':
            pi = []
            cols_index += 1
        else:
            raise CorrelationProcessError(testRebinning, 'test{}.rebin is not properly structured'.format(test_group))
        try:
            while cols[cols_index] != 'sigma':
                pi.append(float(cols[cols_index]))
                cols_index += 1
        except IndexError:
            raise CorrelationProcessError(testRebinning, 'test{}.rebin is not properly structured'.format(test_group))
        sigma = []
        cols_index += 1
        while cols_index < len(cols):
            sigma.append(float(cols[cols_index]))
            cols_index += 1

        pi = np.array(pi)
        sigma = np.array(sigma)

        # load data
        test_data = CorrData('test_rebinning/test{}'.format(test_group), pi, sigma)

        # preform tests
        tests = []
        for line in lines[1:]:
            cols = line.split()
            try:
                assert cols[0].startswith('R') > 0 and (cols[0][1] == 'I' or cols[0][1].isdigit())
            except AssertionError:
                raise CorrelationProcessError(testRebinning, 'test{}.rebin is not properly structured'.format(test_group))

            cols_index = 1
            if cols[cols_index] == 'pi':
                pi = []
                cols_index += 1
            else:
                raise CorrelationProcessError(testRebinning, 'test{}.rebin is not properly structured'.format(test_group))
            try:
                while cols[cols_index] != 'sigma':
                    pi.append(float(cols[cols_index]))
                    cols_index += 1

            except IndexError:
                raise CorrelationProcessError(testRebinning, 'test{}.rebin is not properly structured'.format(test_group))

            sigma = []
            cols_index += 1
            while cols_index < len(cols):
                sigma.append(float(cols[cols_index]))
                cols_index += 1

            pi = np.array(pi)
            sigma = np.array(sigma)
            tests.append((cols[0], np.copy(pi), np.copy(sigma)))

        # save results to disk
        results = []
        for name, pi, sigma in tests:
            if name[1].isdigit():
                transf_matrix = test_data.computeTransformationMatrix(pi, sigma)
                cov_mat_new, data_mat_new, tmp, tmp, tmp = test_data.rebinData(transf_matrix)

                result = '{} data'.format(name)
                for item in data_mat_new:
                    result += ' {:.4f}'.format(item)

                result += ' cov'
                for items in cov_mat_new:
                    for item in items:
                        result += ' {:.4f}'.format(item)

                results.append(result)
            else:
                data_mat_new = rebinIgnoringCovMat(test_data, pi, sigma)
                result = '{} data'.format(name)
                for item in data_mat_new:
                    result += ' {:.4f}'.format(item)

                results.append(result)

        output_file = open('test_rebinning/test{}.res'.format(test_group), 'w')
        output_file.write('\n'.join(results))
        output_file.close()

        # compare the results against the provided solution
        try:
            lines_solution = open('test_rebinning/test{}.sol'.format(test_group)).readlines()
        except IOError:
            raise CorrelationProcessError(testRebinning, 'missing test{}.sol'.format(test_group))
        lines_results = open('test_rebinning/test{}.res'.format(test_group)).readlines()
        diff = [ line for line in difflib.unified_diff(lines_solution, lines_results, fromfile='test{}.sol'.format(test_group), tofile='test{}.res'.format(test_group), lineterm='') ]
        if len(diff) == 0:
            print 'Test group {} status: PASSED'.format(test_group)
        else:
            print 'Test group {} status: FAILED\nDifferences:'.format(test_group)
            for line in diff:
                if line.startswith('+') > 0 or line.startswith('-') > 0:
                    print line



# what to do if the module is not imported but directly executed
if __name__ == '__main__':
    testRebinning(6)
